{"expireTime":9007200813318094000,"key":"transformer-remark-markdown-html-ast-6fc820f8e4b5b6e7a3952f3c5958fb42-gatsby-remark-imagesgatsby-remark-snippetsgatsby-remark-autolink-headersgatsby-remark-code-titlesgatsby-remark-prismjsgatsby-remark-external-links-","val":{"type":"root","children":[{"type":"element","tagName":"h2","properties":{"id":"basic-operations"},"children":[{"type":"element","tagName":"a","properties":{"href":"#basic-operations","aria-label":"basic operations permalink","class":"anchor"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Basic Operations","position":{"start":{"line":1,"column":4,"offset":3},"end":{"line":1,"column":20,"offset":19}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":1,"column":20,"offset":19}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"initilize-tensors"},"children":[{"type":"element","tagName":"a","properties":{"href":"#initilize-tensors","aria-label":"initilize tensors permalink","class":"anchor"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"initilize tensors","position":{"start":{"line":3,"column":5,"offset":25},"end":{"line":3,"column":22,"offset":42}}}],"position":{"start":{"line":3,"column":1,"offset":21},"end":{"line":3,"column":23,"offset":43}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"(10,10) array with zero elements","position":{"start":{"line":5,"column":1,"offset":45},"end":{"line":5,"column":33,"offset":77}}}],"position":{"start":{"line":5,"column":1,"offset":45},"end":{"line":5,"column":33,"offset":77}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Using python state\nx = tf.zeros([10, 10])\nx += 2  # This is equivalent to x = x + 2, which does not mutate the original\n        # value of x\nprint(x)</code></pre></div>","position":{"start":{"line":6,"column":1,"offset":78},"end":{"line":12,"column":4,"offset":237}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"a-simplest-training-using-mnist-datase"},"children":[{"type":"element","tagName":"a","properties":{"href":"#a-simplest-training-using-mnist-datase","aria-label":"a simplest training using mnist datase permalink","class":"anchor"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"A simplest training using mnist datase","position":{"start":{"line":16,"column":5,"offset":245},"end":{"line":16,"column":43,"offset":283}}}],"position":{"start":{"line":16,"column":1,"offset":241},"end":{"line":16,"column":43,"offset":283}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\n# Generate dummy data\nimport numpy as np\nx_train = np.random.random((1000, 20))\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\nx_test = np.random.random((100, 20))\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, activation=&#39;relu&#39;, input_dim=20))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation=&#39;relu&#39;))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation=&#39;softmax&#39;))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss=&#39;categorical_crossentropy&#39;,\n              optimizer=sgd,\n              metrics=[&#39;accuracy&#39;])\n\nmodel.fit(x_train, y_train,\n          epochs=20,\n          batch_size=128)\nscore = model.evaluate(x_test, y_test, batch_size=128)</code></pre></div>","position":{"start":{"line":18,"column":1,"offset":285},"end":{"line":51,"column":4,"offset":1401}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"a-simplest-training-using-mnist-dataset"},"children":[{"type":"element","tagName":"a","properties":{"href":"#a-simplest-training-using-mnist-dataset","aria-label":"a simplest training using mnist dataset permalink","class":"anchor"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"A simplest training using mnist dataset","position":{"start":{"line":55,"column":5,"offset":1409},"end":{"line":55,"column":44,"offset":1448}}}],"position":{"start":{"line":55,"column":1,"offset":1405},"end":{"line":55,"column":44,"offset":1448}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import tensorflow as tf\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer=&#39;adam&#39;,\n              loss=&#39;sparse_categorical_crossentropy&#39;,\n              metrics=[&#39;accuracy&#39;])\n\nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test, y_test)</code></pre></div>","position":{"start":{"line":57,"column":1,"offset":1450},"end":{"line":76,"column":4,"offset":2041}}},{"type":"text","value":"\n"},{"type":"raw","value":"<a class=\"sbox\" href=\"https://www.digitalocean.com/docs/one-clicks/ghost/\" target=\"_blank\" rel=\"noopener\">\n    <div class=\"sbox-image\">\n        <svg id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"65.2 173.5 180 180\"><style>.st0{fill:#0080ff}</style><g id=\"XMLID_229_\"><g id=\"XMLID_690_\"><g id=\"XMLID_691_\"><g id=\"XMLID_44_\"><g id=\"XMLID_48_\"><path id=\"XMLID_49_\" class=\"st0\" d=\"M155.2 351.7v-34.2c36.2 0 64.3-35.9 50.4-74-5.1-14.1-16.4-25.4-30.5-30.5-38.1-13.8-74 14.2-74 50.4H67c0-57.7 55.8-102.7 116.3-83.8 26.4 8.3 47.5 29.3 55.7 55.7 18.9 60.6-26 116.4-83.8 116.4z\"/></g><path id=\"XMLID_47_\" class=\"st0\" d=\"M155.3 317.6h-34v-34h34z\"/><path id=\"XMLID_46_\" class=\"st0\" d=\"M121.3 343.8H95.1v-26.2h26.2z\"/><path id=\"XMLID_45_\" class=\"st0\" d=\"M95.1 317.6H73.2v-21.9h21.9v21.9z\"/></g></g></g></g></svg>\n    </div>\n    <div class=\"sbox-content\">\n        <h4> Dense layer is the layer refering to every node of neuron is connected to a previous layer. &#x1F449;</h4>\n        <h4> Dense(512) is a fully-connected layer with 512 hidden units. &#x1F604; </h4>\n        <img src=\"https://www.researchgate.net/profile/Igor_Gilitschenski/publication/311920717/figure/fig2/AS:617625239425024@1524264740078/Sample-dense-neural-network-with-2-fully-connected-layers-2-dropout-layers-and-a_Q320.jpg\" alt=\"Smiley face\" height=\"142\" width=\"142\">    \n    </div>\n</a>","position":{"start":{"line":78,"column":1,"offset":2043},"end":{"line":87,"column":5,"offset":3387}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"a-more--complete-training-using-mnist-dataset"},"children":[{"type":"element","tagName":"a","properties":{"href":"#a-more--complete-training-using-mnist-dataset","aria-label":"a more  complete training using mnist dataset permalink","class":"anchor"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"A more  complete training using mnist dataset","position":{"start":{"line":90,"column":5,"offset":3394},"end":{"line":90,"column":50,"offset":3439}}}],"position":{"start":{"line":90,"column":1,"offset":3390},"end":{"line":90,"column":50,"offset":3439}}},{"type":"text","value":"\n"},{"type":"raw","value":"<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == &#39;channels_first&#39;:\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype(&#39;float32&#39;)\nx_test = x_test.astype(&#39;float32&#39;)\nx_train /= 255\nx_test /= 255\nprint(&#39;x_train shape:&#39;, x_train.shape)\nprint(x_train.shape[0], &#39;train samples&#39;)\nprint(x_test.shape[0], &#39;test samples&#39;)\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=&#39;relu&#39;,\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation=&#39;relu&#39;))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=&#39;relu&#39;))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=&#39;softmax&#39;))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=[&#39;accuracy&#39;])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(&#39;Test loss:&#39;, score[0])\nprint(&#39;Test accuracy:&#39;, score[1])</code></pre></div>","position":{"start":{"line":92,"column":1,"offset":3441},"end":{"line":157,"column":4,"offset":5510}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":159,"column":1,"offset":5512}}}}